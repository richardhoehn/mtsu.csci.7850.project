{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ba96bee-7b35-48a2-9660-be126f4fbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchview import draw_graph\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659d8f5-efe4-48fc-9afc-929b44d6953a",
   "metadata": {},
   "source": [
    "# Questions for Professor:\n",
    "* Batch Size... I have 1826 rows in total... It is set to 20?\n",
    "* There is no \"accuracy\" because of the regression and that the results are integers sales?\n",
    "* The Loss is extremly low... WHy would this be the case?\n",
    "* I'm not sure I understand the concept of the sequence length\n",
    "* On the `forward` method of the model I use:\n",
    "  ```\n",
    "    h0 = torch.zeros(num_layers, y.size(0), hidden_size).to(y.device)\n",
    "    c0 = torch.zeros(num_layers, y.size(0), hidden_size).to(y.device)\n",
    "  ```\n",
    "* I somehow had a hard time creating the LSTM network and then adding it to the model.. Will need to work on that some but is it ok?\n",
    "* How would I try to \"un-scale\" the values to plot the prediction vs. the validation values?\n",
    "* Is dropout a good idea?\n",
    "* I used \"4\" for the stacked LSTM layers... is that overkill and should I just stay with \"1\"?\n",
    "* Overall... is the the right approach for this project? It seems a bit general and I havent really contributed to anything meaninful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c452bfb-6c16-4b09-802a-b8e777c60c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config & Setup Details\n",
    "cfg_batch_size  = 20\n",
    "cfg_max_epochs  = 10\n",
    "cfg_num_workers = 2\n",
    "\n",
    "# Learning Config\n",
    "cfg_split        = 0.8\n",
    "cfg_sequence_len = 30\n",
    "\n",
    "# Data Config\n",
    "cfg_data_separator = \",\"\n",
    "cfg_data_date_fmt  = \"%Y-%m-%d\"\n",
    "cfg_data_url_train = \"https://s3.amazonaws.com/mtsu.csci.7850.project/train.csv\"\n",
    "cfg_data_url_test  = \"https://s3.amazonaws.com/mtsu.csci.7850.project/test.csv\"\n",
    "\n",
    "# Logger Config\n",
    "cfg_logger_dir     = \"logs\"\n",
    "cfg_logger_name    = \"Project\"\n",
    "cfg_logger_version = \"data-loader\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d9c2e45-4217-4d40-8f11-0b0d8d57b906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only CPU is available...\n"
     ]
    }
   ],
   "source": [
    "# Setup CPU or GPU Device Settings for CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())\n",
    "    print(torch.cuda.get_device_properties(\"cuda\"))\n",
    "    print(\"Number of devices:\",torch.cuda.device_count())\n",
    "    device = (\"cuda\")\n",
    "else:\n",
    "    print(\"Only CPU is available...\")\n",
    "    device = (\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7434bc9f-b965-4032-8c7a-f069c91761f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Shape: (913000, 4)\n",
      "        date  store  item  sales\n",
      "0 2013-01-01      1     1     13\n",
      "1 2013-01-02      1     1     11\n",
      "2 2013-01-03      1     1     14\n",
      "3 2013-01-04      1     1     13\n",
      "4 2013-01-05      1     1     10\n",
      "********\n",
      "\n",
      "Grouped by Date Shape: (1826, 2)\n",
      "           date  sales\n",
      "0    2013-01-01  13696\n",
      "1    2013-01-02  13678\n",
      "2    2013-01-03  14488\n",
      "3    2013-01-04  15677\n",
      "4    2013-01-05  16237\n",
      "...         ...    ...\n",
      "1821 2017-12-27  20378\n",
      "1822 2017-12-28  21885\n",
      "1823 2017-12-29  23535\n",
      "1824 2017-12-30  24988\n",
      "1825 2017-12-31  26420\n",
      "\n",
      "[1826 rows x 2 columns]\n",
      "********\n",
      "\n",
      "Grouped by Date & Store Shape: (18260, 3)\n",
      "            date  store  sales\n",
      "0     2013-01-01      1   1316\n",
      "1     2013-01-01      2   1742\n",
      "2     2013-01-01      3   1588\n",
      "3     2013-01-01      4   1423\n",
      "4     2013-01-01      5   1032\n",
      "...          ...    ...    ...\n",
      "18255 2017-12-31      6   2009\n",
      "18256 2017-12-31      7   1831\n",
      "18257 2017-12-31      8   3205\n",
      "18258 2017-12-31      9   2774\n",
      "18259 2017-12-31     10   2939\n",
      "\n",
      "[18260 rows x 3 columns]\n",
      "********\n",
      "\n",
      "Training Shape: (1826, 11)\n",
      "store       date     1     2     3     4     5     6     7     8     9    10\n",
      "0     2013-01-01  1316  1742  1588  1423  1032  1099   964  1628  1383  1521\n",
      "1     2013-01-02  1264  1808  1538  1432   997  1023   944  1687  1455  1530\n",
      "2     2013-01-03  1305  1887  1635  1534  1130  1149   966  1736  1492  1654\n",
      "3     2013-01-04  1452  1983  1741  1685  1258  1201  1040  1966  1612  1739\n",
      "4     2013-01-05  1499  2087  1887  1649  1154  1286  1131  2005  1698  1841\n",
      "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
      "1821  2017-12-27  1837  2624  2365  2176  1552  1560  1471  2468  2104  2221\n",
      "1822  2017-12-28  1951  2839  2479  2306  1696  1707  1509  2660  2309  2429\n",
      "1823  2017-12-29  2116  3025  2646  2460  1774  1737  1689  2923  2478  2687\n",
      "1824  2017-12-30  2304  3151  2885  2637  1922  1877  1721  3109  2640  2742\n",
      "1825  2017-12-31  2388  3370  3086  2844  1974  2009  1831  3205  2774  2939\n",
      "\n",
      "[1826 rows x 11 columns]\n",
      "Training Cols: Index(['date', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype='object', name='store')\n",
      "********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Data - Parse the Date Column\n",
    "df_raw = pd.read_csv(cfg_data_url_train, parse_dates=[\"date\"])\n",
    "\n",
    "print(f\"Raw Shape: {df_raw.shape}\")\n",
    "print(df_raw.head())\n",
    "print(\"********\\n\")\n",
    "\n",
    "# Format Date Column to DateTime\n",
    "df_raw['date'] = pd.to_datetime(df_raw['date'], format=cfg_data_date_fmt)\n",
    "\n",
    "df_grouped_date_store = df_raw.groupby(['date', 'store'])['sales'].sum().reset_index()\n",
    "df_grouped_date = df_raw.groupby(['date'])['sales'].sum().reset_index()\n",
    "\n",
    "print(f\"Grouped by Date Shape: {df_grouped_date.shape}\")\n",
    "print(df_grouped_date)\n",
    "print(\"********\\n\")\n",
    "\n",
    "print(f\"Grouped by Date & Store Shape: {df_grouped_date_store.shape}\")\n",
    "print(df_grouped_date_store)\n",
    "print(\"********\\n\")\n",
    "\n",
    "# Pivot the DataFrame\n",
    "df_train = df_grouped_date_store.pivot(index='date', columns='store', values='sales')\n",
    "\n",
    "# Resetting the index\n",
    "df_train = df_train.reset_index()\n",
    "\n",
    "# Show the New Table\n",
    "print(f\"Training Shape: {df_train.shape}\")\n",
    "print(df_train)\n",
    "print(f\"Training Cols: {df_train.columns}\")\n",
    "print(\"********\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19d512fb-f092-446b-ba5e-b343ea5d8acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Shape: (1826, 10)\n"
     ]
    }
   ],
   "source": [
    "# Setup the Dataframe being used\n",
    "df = df_train # Simple Copy\n",
    "df.set_index('date', inplace=True)\n",
    "print(f\"DF Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f41c9b8c-cc1b-4cea-988c-735c38133505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Scaled Shape: (1826, 10)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "print(f\"DF Scaled Shape: {df_scaled.shape}\")\n",
    "\n",
    "# Function to Create the Sequence\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Create sequences\n",
    "seq_length = 30\n",
    "x, y = create_sequences(df_scaled, seq_length)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(cfg_split * len(x_tensor))\n",
    "\n",
    "x_train = x_tensor[:train_size]\n",
    "y_train = y_tensor[:train_size]\n",
    "\n",
    "x_val = x_tensor[train_size:]\n",
    "y_val = y_tensor[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5d8017d-ef71-4785-9e9d-2db2f2dae877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Shape: (1795, 30, 10)\n",
      "y Shape: (1795, 10)\n",
      "\n",
      "x_train Shape: torch.Size([1436, 30, 10])\n",
      "y_train Shape: torch.Size([1436, 10])\n",
      "\n",
      "x_val Shape: torch.Size([359, 30, 10])\n",
      "y_val Shape: torch.Size([359, 10])\n"
     ]
    }
   ],
   "source": [
    "print(f\"x Shape: {x.shape}\")\n",
    "print(f\"y Shape: {y.shape}\")\n",
    "print(\"\")\n",
    "print(f\"x_train Shape: {x_train.shape}\")\n",
    "print(f\"y_train Shape: {y_train.shape}\")\n",
    "print(\"\")\n",
    "print(f\"x_val Shape: {x_val.shape}\")\n",
    "print(f\"y_val Shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6466407a-73a5-480c-8123-fc1631a06e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 hidden_size, \n",
    "                 output_size, \n",
    "                 num_layers,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    # No complications with regression...\n",
    "    def predict(self, x):\n",
    "        return self(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        \n",
    "        # Initialize hidden state and cell state\n",
    "        # Found this on the internet - Not sure about it\n",
    "        h0 = torch.zeros(num_layers, y.size(0), hidden_size).to(y.device)\n",
    "        c0 = torch.zeros(num_layers, y.size(0), hidden_size).to(y.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        y, _ = self.lstm(y, (h0, c0))\n",
    "        y = y[:, -1, :] # Extract only the last time step\n",
    "        y = self.linear(y) # Using linear to bring back to output_size\n",
    "        return y\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        x, y_true = train_batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y_pred, y_true)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y_true = val_batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y_pred, y_true)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "input_size  = 10 # Number of features (sales data from 10 stores)\n",
    "hidden_size = 50 # Number of features in hidden state\n",
    "output_size = 10 # Number of output values (future sales prediction)\n",
    "num_layers  = 4  # Number of stacked LSTM layers\n",
    "\n",
    "# Create the LSTM model\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13f87241-11f5-4cf1-aa57-e4bc952171ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTMModel                                [5, 10]                   --\n",
       "├─LSTM: 1-1                              [5, 30, 50]               73,600\n",
       "├─Linear: 1-2                            [5, 10]                   510\n",
       "==========================================================================================\n",
       "Total params: 74,110\n",
       "Trainable params: 74,110\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 11.04\n",
       "==========================================================================================\n",
       "Input size (MB): 2.15\n",
       "Forward/backward pass size (MB): 0.06\n",
       "Params size (MB): 0.30\n",
       "Estimated Total Size (MB): 2.51\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_data=torch.Tensor(x_train[0:5]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2da7029-b357-4293-971b-c5496b7257f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.1.0 (20230707.2238)\n",
       " -->\n",
       "<!-- Title: model Pages: 1 -->\n",
       "<svg width=\"471pt\" height=\"364pt\"\n",
       " viewBox=\"0.00 0.00 470.88 363.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 359.5)\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-359.5 466.88,-359.5 466.88,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"128.75,-351.25 0,-351.25 0,-315.75 128.75,-315.75 128.75,-351.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-315.75 0,-351.25 69.25,-351.25 69.25,-315.75 0,-315.75\"/>\n",
       "<text text-anchor=\"start\" x=\"5\" y=\"-336.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"16.25\" y=\"-324\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"69.25,-315.75 69.25,-351.25 128.75,-351.25 128.75,-315.75 69.25,-315.75\"/>\n",
       "<text text-anchor=\"start\" x=\"74.25\" y=\"-330.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(5, 30, 10)</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"332.88,-275.5 109.88,-275.5 109.88,-231.5 332.88,-231.5 332.88,-275.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"109.88,-231.5 109.88,-275.5 155.88,-275.5 155.88,-231.5 109.88,-231.5\"/>\n",
       "<text text-anchor=\"start\" x=\"119.75\" y=\"-256.75\" font-family=\"Linux libertine\" font-size=\"10.00\">LSTM</text>\n",
       "<text text-anchor=\"start\" x=\"114.5\" y=\"-244\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"155.88,-253.5 155.88,-275.5 202.88,-275.5 202.88,-253.5 155.88,-253.5\"/>\n",
       "<text text-anchor=\"start\" x=\"165.5\" y=\"-261\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"202.88,-253.5 202.88,-275.5 332.88,-275.5 332.88,-253.5 202.88,-253.5\"/>\n",
       "<text text-anchor=\"start\" x=\"207.88\" y=\"-261\" font-family=\"Linux libertine\" font-size=\"10.00\">(5, 30, 10), 2 x (4, 5, 50) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"155.88,-231.5 155.88,-253.5 202.88,-253.5 202.88,-231.5 155.88,-231.5\"/>\n",
       "<text text-anchor=\"start\" x=\"160.62\" y=\"-239\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"202.88,-231.5 202.88,-253.5 332.88,-253.5 332.88,-231.5 202.88,-231.5\"/>\n",
       "<text text-anchor=\"start\" x=\"207.88\" y=\"-239\" font-family=\"Linux libertine\" font-size=\"10.00\">(5, 30, 50), 2 x (4, 5, 50) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;3 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.06,-315.77C118.87,-305.43 146,-291.95 169.52,-280.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.95,-282.96 178.35,-275.38 167.83,-276.7 170.95,-282.96\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"295.88,-355.5 146.88,-355.5 146.88,-311.5 295.88,-311.5 295.88,-355.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"146.88,-311.5 146.88,-355.5 192.88,-355.5 192.88,-311.5 146.88,-311.5\"/>\n",
       "<text text-anchor=\"start\" x=\"165\" y=\"-336.75\" font-family=\"Linux libertine\" font-size=\"10.00\">to</text>\n",
       "<text text-anchor=\"start\" x=\"151.5\" y=\"-324\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"192.88,-333.5 192.88,-355.5 239.88,-355.5 239.88,-333.5 192.88,-333.5\"/>\n",
       "<text text-anchor=\"start\" x=\"202.5\" y=\"-341\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"239.88,-333.5 239.88,-355.5 295.88,-355.5 295.88,-333.5 239.88,-333.5\"/>\n",
       "<text text-anchor=\"start\" x=\"244.62\" y=\"-341\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 5, 50) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"192.88,-311.5 192.88,-333.5 239.88,-333.5 239.88,-311.5 192.88,-311.5\"/>\n",
       "<text text-anchor=\"start\" x=\"197.62\" y=\"-319\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"239.88,-311.5 239.88,-333.5 295.88,-333.5 295.88,-311.5 239.88,-311.5\"/>\n",
       "<text text-anchor=\"start\" x=\"244.62\" y=\"-319\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 5, 50) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M221.38,-311.6C221.38,-303.82 221.38,-294.8 221.38,-286.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.88,-286.46 221.38,-276.46 217.88,-286.46 224.88,-286.46\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"462.88,-355.5 313.88,-355.5 313.88,-311.5 462.88,-311.5 462.88,-355.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"313.88,-311.5 313.88,-355.5 359.88,-355.5 359.88,-311.5 313.88,-311.5\"/>\n",
       "<text text-anchor=\"start\" x=\"332\" y=\"-336.75\" font-family=\"Linux libertine\" font-size=\"10.00\">to</text>\n",
       "<text text-anchor=\"start\" x=\"318.5\" y=\"-324\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"359.88,-333.5 359.88,-355.5 406.88,-355.5 406.88,-333.5 359.88,-333.5\"/>\n",
       "<text text-anchor=\"start\" x=\"369.5\" y=\"-341\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"406.88,-333.5 406.88,-355.5 462.88,-355.5 462.88,-333.5 406.88,-333.5\"/>\n",
       "<text text-anchor=\"start\" x=\"411.62\" y=\"-341\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 5, 50) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"359.88,-311.5 359.88,-333.5 406.88,-333.5 406.88,-311.5 359.88,-311.5\"/>\n",
       "<text text-anchor=\"start\" x=\"364.62\" y=\"-319\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"406.88,-311.5 406.88,-333.5 462.88,-333.5 462.88,-311.5 406.88,-311.5\"/>\n",
       "<text text-anchor=\"start\" x=\"411.62\" y=\"-319\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 5, 50) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M343.62,-311.6C322.84,-301.89 297.95,-290.27 276.07,-280.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"277.79,-276.52 267.25,-275.46 274.83,-282.86 277.79,-276.52\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"310.38,-195.5 132.38,-195.5 132.38,-151.5 310.38,-151.5 310.38,-195.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"132.38,-151.5 132.38,-195.5 201.38,-195.5 201.38,-151.5 132.38,-151.5\"/>\n",
       "<text text-anchor=\"start\" x=\"137.25\" y=\"-176.75\" font-family=\"Linux libertine\" font-size=\"10.00\">__getitem__</text>\n",
       "<text text-anchor=\"start\" x=\"148.5\" y=\"-164\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"201.38,-173.5 201.38,-195.5 248.38,-195.5 248.38,-173.5 201.38,-173.5\"/>\n",
       "<text text-anchor=\"start\" x=\"211\" y=\"-181\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"248.38,-173.5 248.38,-195.5 310.38,-195.5 310.38,-173.5 248.38,-173.5\"/>\n",
       "<text text-anchor=\"start\" x=\"253.12\" y=\"-181\" font-family=\"Linux libertine\" font-size=\"10.00\">(5, 30, 50) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"201.38,-151.5 201.38,-173.5 248.38,-173.5 248.38,-151.5 201.38,-151.5\"/>\n",
       "<text text-anchor=\"start\" x=\"206.12\" y=\"-159\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"248.38,-151.5 248.38,-173.5 310.38,-173.5 310.38,-151.5 248.38,-151.5\"/>\n",
       "<text text-anchor=\"start\" x=\"262.12\" y=\"-159\" font-family=\"Linux libertine\" font-size=\"10.00\">(5, 50) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M221.38,-231.6C221.38,-223.82 221.38,-214.8 221.38,-206.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.88,-206.46 221.38,-196.46 217.88,-206.46 224.88,-206.46\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"289.88,-115.5 152.88,-115.5 152.88,-71.5 289.88,-71.5 289.88,-115.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"152.88,-71.5 152.88,-115.5 198.88,-115.5 198.88,-71.5 152.88,-71.5\"/>\n",
       "<text text-anchor=\"start\" x=\"160.88\" y=\"-96.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"157.5\" y=\"-84\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"198.88,-93.5 198.88,-115.5 245.88,-115.5 245.88,-93.5 198.88,-93.5\"/>\n",
       "<text text-anchor=\"start\" x=\"208.5\" y=\"-101\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"245.88,-93.5 245.88,-115.5 289.88,-115.5 289.88,-93.5 245.88,-93.5\"/>\n",
       "<text text-anchor=\"start\" x=\"250.62\" y=\"-101\" font-family=\"Linux libertine\" font-size=\"10.00\">(5, 50) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"198.88,-71.5 198.88,-93.5 245.88,-93.5 245.88,-71.5 198.88,-71.5\"/>\n",
       "<text text-anchor=\"start\" x=\"203.62\" y=\"-79\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"245.88,-71.5 245.88,-93.5 289.88,-93.5 289.88,-71.5 245.88,-71.5\"/>\n",
       "<text text-anchor=\"start\" x=\"250.62\" y=\"-79\" font-family=\"Linux libertine\" font-size=\"10.00\">(5, 10) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M221.38,-151.6C221.38,-143.82 221.38,-134.8 221.38,-126.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.88,-126.46 221.38,-116.46 217.88,-126.46 224.88,-126.46\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"280.12,-35.5 162.62,-35.5 162.62,0 280.12,0 280.12,-35.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"162.62,0 162.62,-35.5 238.62,-35.5 238.62,0 162.62,0\"/>\n",
       "<text text-anchor=\"start\" x=\"167.62\" y=\"-21\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"182.25\" y=\"-8.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"238.62,0 238.62,-35.5 280.12,-35.5 280.12,0 238.62,0\"/>\n",
       "<text text-anchor=\"start\" x=\"243.62\" y=\"-14.62\" font-family=\"Linux libertine\" font-size=\"10.00\">(5, 10)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M221.38,-71.56C221.38,-63.6 221.38,-54.41 221.38,-45.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.88,-46.05 221.38,-36.05 217.88,-46.05 224.88,-46.05\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f294441cc50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_graph = draw_graph(model,\n",
    "                         input_data=torch.Tensor(x_train[0:5]).float(),\n",
    "                         device=device,\n",
    "                         hide_inner_tensors=True,\n",
    "                         hide_module_functions=True,\n",
    "                         expand_nested=False,\n",
    "                         depth=3,\n",
    "                         dtypes=[torch.long])\n",
    "\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "643df836-e85a-4d03-8226-fc56cf8b3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_train = torch.utils.data.DataLoader(list(zip(torch.Tensor(x_train).float(),\n",
    "                                                torch.Tensor(y_train).float())), \n",
    "                                       shuffle=True, \n",
    "                                       batch_size=cfg_batch_size, \n",
    "                                       num_workers=cfg_num_workers)\n",
    "\n",
    "xy_val = torch.utils.data.DataLoader(list(zip(torch.Tensor(x_val).float(), \n",
    "                                              torch.Tensor(y_val).float())), \n",
    "                                     shuffle=False, \n",
    "                                     batch_size=cfg_batch_size, \n",
    "                                     num_workers=cfg_num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97c23877-fe6c-4154-8233-5aff37f0a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pl.loggers.CSVLogger(\"lightning_logs\", \n",
    "                              name=\"Project\",\n",
    "                              version=\"1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f02ae27-a084-4d2b-bab9-af0a4b32c53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(logger=logger, max_epochs=cfg_max_epochs,\n",
    "                     enable_progress_bar=True,\n",
    "                     log_every_n_steps=0,\n",
    "                     enable_checkpointing=False, \n",
    "                     callbacks=[pl.callbacks.TQDMProgressBar(refresh_rate=50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "434715be-7a7c-46cc-af84-f64d25ed572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/lightning/fabric/loggers/csv_logs.py:195: UserWarning:\n",
      "\n",
      "Experiment logs directory lightning_logs/Project/1.0.0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "\n",
      "/opt/conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning:\n",
      "\n",
      "The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f866d01045584bdf94cdc1eea9a5ca2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">  Runningstage.validating  </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34516283869743347    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m Runningstage.validating \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34516283869743347   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.34516283869743347}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, xy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2623d1a3-44a6-4d6a-921d-9c9756e2ff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type    | Params\n",
      "-----------------------------------\n",
      "0 | lstm   | LSTM    | 73.6 K\n",
      "1 | linear | Linear  | 510   \n",
      "2 | loss   | MSELoss | 0     \n",
      "-----------------------------------\n",
      "74.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "74.1 K    Total params\n",
      "0.296     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning:\n",
      "\n",
      "The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9060a3f387334810bc4dbcca81c0a947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, xy_train, xy_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d8f4eda-2701-4e45-a1b4-a182912431fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018450</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.052930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017208</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>0.013740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015468</td>\n",
       "      <td>2</td>\n",
       "      <td>215</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>215</td>\n",
       "      <td>0.012130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.015537</td>\n",
       "      <td>3</td>\n",
       "      <td>287</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>287</td>\n",
       "      <td>0.013338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015046</td>\n",
       "      <td>4</td>\n",
       "      <td>359</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>359</td>\n",
       "      <td>0.011843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.014634</td>\n",
       "      <td>5</td>\n",
       "      <td>431</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>431</td>\n",
       "      <td>0.011952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.014184</td>\n",
       "      <td>6</td>\n",
       "      <td>503</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>503</td>\n",
       "      <td>0.011171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.007836</td>\n",
       "      <td>7</td>\n",
       "      <td>575</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>575</td>\n",
       "      <td>0.008430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004763</td>\n",
       "      <td>8</td>\n",
       "      <td>647</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>647</td>\n",
       "      <td>0.005483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003848</td>\n",
       "      <td>9</td>\n",
       "      <td>719</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>719</td>\n",
       "      <td>0.003394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_loss  epoch  step  train_loss\n",
       "0   0.345163      0     0         NaN\n",
       "1   0.018450      0    71         NaN\n",
       "2        NaN      0    71    0.052930\n",
       "3   0.017208      1   143         NaN\n",
       "4        NaN      1   143    0.013740\n",
       "5   0.015468      2   215         NaN\n",
       "6        NaN      2   215    0.012130\n",
       "7   0.015537      3   287         NaN\n",
       "8        NaN      3   287    0.013338\n",
       "9   0.015046      4   359         NaN\n",
       "10       NaN      4   359    0.011843\n",
       "11  0.014634      5   431         NaN\n",
       "12       NaN      5   431    0.011952\n",
       "13  0.014184      6   503         NaN\n",
       "14       NaN      6   503    0.011171\n",
       "15  0.007836      7   575         NaN\n",
       "16       NaN      7   575    0.008430\n",
       "17  0.004763      8   647         NaN\n",
       "18       NaN      8   647    0.005483\n",
       "19  0.003848      9   719         NaN\n",
       "20       NaN      9   719    0.003394"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(logger.log_dir+\"/metrics.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9156268-0afc-4513-ae82-b468ec25d875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results[\"epoch\"][np.logical_not(np.isnan(results[\"train_loss\"]))],\n",
    "         results[\"train_loss\"][np.logical_not(np.isnan(results[\"train_loss\"]))],\n",
    "         label=\"Training\")\n",
    "\n",
    "plt.plot(results[\"epoch\"][np.logical_not(np.isnan(results[\"val_loss\"]))], \n",
    "         results[\"val_loss\"][np.logical_not(np.isnan(results[\"val_loss\"]))], \n",
    "         label=\"Validation\")\n",
    "\n",
    "plt.legend() \n",
    "plt.ylabel(\"MSE Loss\") \n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18902a84-c60c-498f-981a-db4a2be6a149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
